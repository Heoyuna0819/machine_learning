{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Heoyuna0819/machine_learning/blob/main/Mhealth_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7gLjYWENIFO",
        "outputId": "7354c5cd-4b09-4bb3-ec2c-216df87a0e2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(343195, 25)\n",
            "   chest_acc_x  chest_acc_y  chest_acc_z     ecg_1     ecg_2  ankle_acc_x  \\\n",
            "0      -9.7788      0.55690      1.19750  0.008373 -0.033490       2.6493   \n",
            "1      -9.7733      0.27880      0.73036 -0.025118 -0.025118       2.4157   \n",
            "2      -9.8609      0.11561      0.79988  0.025118  0.016745       2.3865   \n",
            "3      -9.7409      0.17652      0.88957  0.180010  0.129770       2.3758   \n",
            "4      -9.7821      0.21637      0.90368  0.092098  0.046049       2.3239   \n",
            "\n",
            "   ankle_acc_y  ankle_acc_z  ankle_gyro_x  ankle_gyro_y  ...  arm_acc_y  \\\n",
            "0      -9.4517      0.37683      -0.20965      -0.88931  ...    -9.0618   \n",
            "1      -9.5306      0.40179      -0.20965      -0.88931  ...    -9.2048   \n",
            "2      -9.5991      0.48141      -0.20037      -0.86867  ...    -9.1945   \n",
            "3      -9.5997      0.42919      -0.20037      -0.86867  ...    -9.1746   \n",
            "4      -9.5406      0.40038      -0.20037      -0.86867  ...    -9.2039   \n",
            "\n",
            "   arm_acc_z  arm_gyro_x  arm_gyro_y  arm_gyro_z  arm_mag_x  arm_mag_y  \\\n",
            "0     1.8177   -0.058824    -0.93429    -0.34483   0.355370   -0.37003   \n",
            "1     1.5189   -0.058824    -0.93429    -0.34483   0.719910    0.17803   \n",
            "2     1.5507   -0.058824    -0.93429    -0.34483   0.355370   -0.37003   \n",
            "3     1.5413   -0.078431    -0.93429    -0.34052   0.357180   -0.18858   \n",
            "4     1.6127   -0.078431    -0.93429    -0.34052  -0.001887   -0.18867   \n",
            "\n",
            "   arm_mag_z  label  subject  \n",
            "0   -0.35020      1        1  \n",
            "1    0.37363      1        1  \n",
            "2   -0.35020      1        1  \n",
            "3   -0.35198      1        1  \n",
            "4   -0.72017      1        1  \n",
            "\n",
            "[5 rows x 25 columns]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 데이터셋 경로 설정\n",
        "DATA_DIR = \"/content/drive/MyDrive/MHEALTHDATASET\"\n",
        "\n",
        "# UCI MHEALTH dataset 컬럼 정의\n",
        "COLS = [\n",
        "    \"chest_acc_x\",\"chest_acc_y\",\"chest_acc_z\",\n",
        "    \"ecg_1\",\"ecg_2\",\n",
        "    \"ankle_acc_x\",\"ankle_acc_y\",\"ankle_acc_z\",\n",
        "    \"ankle_gyro_x\",\"ankle_gyro_y\",\"ankle_gyro_z\",\n",
        "    \"ankle_mag_x\",\"ankle_mag_y\",\"ankle_mag_z\",\n",
        "    \"arm_acc_x\",\"arm_acc_y\",\"arm_acc_z\",\n",
        "    \"arm_gyro_x\",\"arm_gyro_y\",\"arm_gyro_z\",\n",
        "    \"arm_mag_x\",\"arm_mag_y\",\"arm_mag_z\",\n",
        "    \"label\"\n",
        "]\n",
        "\n",
        "# 모든 subject 데이터 읽어서 합치기\n",
        "dfs = []\n",
        "for sid in range(1, 11):  # subject 1~10\n",
        "    file_path = os.path.join(DATA_DIR, f\"mHealth_subject{sid}.log\")\n",
        "    df = pd.read_csv(file_path, sep=\"\\t\", header=None, names=COLS)\n",
        "    df[\"subject\"] = sid   # subject 번호 추가\n",
        "    dfs.append(df)\n",
        "\n",
        "# 하나의 DataFrame으로 합치기\n",
        "full_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Null 클래스(라벨=0)는 제거\n",
        "full_df = full_df[full_df[\"label\"] != 0].reset_index(drop=True)\n",
        "\n",
        "print(full_df.shape)\n",
        "print(full_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxDlZdL9NdPY",
        "outputId": "aae5e8fc-aa41-41c7-9af7-5861f47349aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_all shape: (6849, 100, 23)\n",
            "y_all shape: (6849,)\n",
            "subject unique: [ 1  2  3  4  5  6  7  8  9 10]\n",
            "라벨 분포(1~12): [610 615 615 614 608 567 587 587 614 614 616 202]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 윈도우 크기 & stride\n",
        "FS = 50          # 주파수 50Hz\n",
        "WIN = 2 * FS     # 2초 = 100 샘플\n",
        "STRIDE = WIN // 2  # 절반 겹치기 = 50 샘플\n",
        "\n",
        "# feature 컬럼 (라벨과 subject 제외)\n",
        "FEATURE_COLS = [c for c in full_df.columns if c not in [\"label\", \"subject\"]]\n",
        "\n",
        "def make_windows_by_subject(df, min_ratio=0.0):\n",
        "    Xs, ys, subs = [], [], []\n",
        "\n",
        "    # subject별로 안전하게 자르기\n",
        "    for sid, part in df.groupby(\"subject\", sort=True):\n",
        "        arr = part[FEATURE_COLS].values.astype(np.float32)  # (N_s, 23)\n",
        "        labels = part[\"label\"].values.astype(np.int32)      # (N_s,)\n",
        "        n = len(part)\n",
        "        i = 0\n",
        "        while i + WIN <= n:\n",
        "            w_labels = labels[i:i+WIN]\n",
        "            w_vals = arr[i:i+WIN]\n",
        "\n",
        "            # 최빈값(label)과 비율\n",
        "            binc = np.bincount(w_labels)\n",
        "            maj = np.argmax(binc)\n",
        "            maj_ratio = binc[maj] / WIN\n",
        "\n",
        "            if maj_ratio >= min_ratio:\n",
        "                Xs.append(w_vals)\n",
        "                ys.append(maj)\n",
        "                subs.append(sid)\n",
        "\n",
        "            i += STRIDE\n",
        "\n",
        "    X = np.array(Xs)             # (num_windows, 100, 23)\n",
        "    y = np.array(ys, dtype=int)  # (num_windows,)\n",
        "    s = np.array(subs, dtype=int)\n",
        "    return X, y, s\n",
        "\n",
        "\n",
        "X_all, y_all, s_all = make_windows_by_subject(full_df, min_ratio=0.0)\n",
        "\n",
        "print(\"X_all shape:\", X_all.shape)\n",
        "print(\"y_all shape:\", y_all.shape)\n",
        "print(\"subject unique:\", np.unique(s_all))\n",
        "# 라벨 1~12 분포\n",
        "counts = np.bincount(y_all)\n",
        "print(\"라벨 분포(1~12):\", counts[1:13])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZVj14xwN006",
        "outputId": "66925a0f-465e-4d8c-8e27-4abc4d66ff25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 | Test subjects=(1, 2)\n",
            "  Train set: (5438, 100, 23) (5438,)\n",
            "  Test set : (1411, 100, 23) (1411,)\n",
            "Fold 2 | Test subjects=(3, 4)\n",
            "  Train set: (5438, 100, 23) (5438,)\n",
            "  Test set : (1411, 100, 23) (1411,)\n",
            "Fold 3 | Test subjects=(5, 6)\n",
            "  Train set: (5529, 100, 23) (5529,)\n",
            "  Test set : (1320, 100, 23) (1320,)\n",
            "Fold 4 | Test subjects=(7, 8)\n",
            "  Train set: (5500, 100, 23) (5500,)\n",
            "  Test set : (1349, 100, 23) (1349,)\n",
            "Fold 5 | Test subjects=(9, 10)\n",
            "  Train set: (5491, 100, 23) (5491,)\n",
            "  Test set : (1358, 100, 23) (1358,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 5개 그룹\n",
        "pairs = [(1,2), (3,4), (5,6), (7,8), (9,10)]\n",
        "\n",
        "def split_by_subject(X, y, s, test_pair):\n",
        "    \"\"\"\n",
        "    X: 윈도우 입력 데이터 (shape: [N, T, D])\n",
        "    y: 라벨 (shape: [N])\n",
        "    s: subject 번호 (shape: [N])\n",
        "    test_pair: (예: (1,2)) 테스트 subject 번호 쌍\n",
        "    \"\"\"\n",
        "    test_mask = np.isin(s, test_pair)   # 테스트셋에 해당하는 subject만 True\n",
        "    X_train, y_train = X[~test_mask], y[~test_mask]\n",
        "    X_test,  y_test  = X[test_mask],  y[test_mask]\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "# 다섯 fold 순환\n",
        "for i, pair in enumerate(pairs, 1):\n",
        "    X_tr, y_tr, X_te, y_te = split_by_subject(X_all, y_all, s_all, pair)\n",
        "    print(f\"Fold {i} | Test subjects={pair}\")\n",
        "    print(\"  Train set:\", X_tr.shape, y_tr.shape)\n",
        "    print(\"  Test set :\", X_te.shape, y_te.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0zjk7WaN5bj",
        "outputId": "38bcf13f-add7-4cd6-fde9-11330e6381d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 | Test subjects=(1, 2)\n",
            "  Train set: (5438, 100, 23) (5438,)\n",
            "  Test set : (1411, 100, 23) (1411,)\n",
            "  평균: -1.097  | 표준편차: 14.805\n",
            "--------------------------------------------------\n",
            "Fold 2 | Test subjects=(3, 4)\n",
            "  Train set: (5438, 100, 23) (5438,)\n",
            "  Test set : (1411, 100, 23) (1411,)\n",
            "  평균: -1.105  | 표준편차: 14.749\n",
            "--------------------------------------------------\n",
            "Fold 3 | Test subjects=(5, 6)\n",
            "  Train set: (5529, 100, 23) (5529,)\n",
            "  Test set : (1320, 100, 23) (1320,)\n",
            "  평균: -1.076  | 표준편차: 14.514\n",
            "--------------------------------------------------\n",
            "Fold 4 | Test subjects=(7, 8)\n",
            "  Train set: (5500, 100, 23) (5500,)\n",
            "  Test set : (1349, 100, 23) (1349,)\n",
            "  평균: -1.137  | 표준편차: 14.941\n",
            "--------------------------------------------------\n",
            "Fold 5 | Test subjects=(9, 10)\n",
            "  Train set: (5491, 100, 23) (5491,)\n",
            "  Test set : (1358, 100, 23) (1358,)\n",
            "  평균: -1.045  | 표준편차: 14.942\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 5개 그룹\n",
        "pairs = [(1,2), (3,4), (5,6), (7,8), (9,10)]\n",
        "\n",
        "def split_by_subject(X, y, s, test_pair):\n",
        "    test_mask = np.isin(s, test_pair)\n",
        "    X_train, y_train = X[~test_mask], y[~test_mask]\n",
        "    X_test,  y_test  = X[test_mask],  y[test_mask]\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "def standardize(train_X, test_X):\n",
        "\n",
        "    # 훈련 데이터 기준으로 mean/std 계산\n",
        "    mean = train_X.mean(axis=(0,1), keepdims=True)\n",
        "    std = train_X.std(axis=(0,1), keepdims=True)\n",
        "    std[std == 0] = 1.0\n",
        "\n",
        "    # 표준화 적용\n",
        "    train_X = (train_X - mean) / std\n",
        "    test_X  = (test_X  - mean) / std\n",
        "    return train_X, test_X, mean, std\n",
        "\n",
        "# 5-Fold 교차검증용 루프\n",
        "for i, pair in enumerate(pairs, 1):\n",
        "    X_tr, y_tr, X_te, y_te = split_by_subject(X_all, y_all, s_all, pair)\n",
        "    X_tr, X_te, mean, std = standardize(X_tr, X_te)\n",
        "\n",
        "    print(f\"Fold {i} | Test subjects={pair}\")\n",
        "    print(\"  Train set:\", X_tr.shape, y_tr.shape)\n",
        "    print(\"  Test set :\", X_te.shape, y_te.shape)\n",
        "    print(\"  평균:\", np.round(mean.mean(), 3), \" | 표준편차:\", np.round(std.mean(), 3))\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Utility\n",
        "\n",
        "def one_hot(y, num_classes):\n",
        "    oh = np.zeros((y.shape[0], num_classes), dtype=np.float32)\n",
        "    oh[np.arange(y.shape[0]), y - 1] = 1.0\n",
        "    return oh\n",
        "\n",
        "def softmax(x):\n",
        "    x = x - x.max(axis=1, keepdims=True)\n",
        "    e = np.exp(x)\n",
        "    return e / (e.sum(axis=1, keepdims=True) + 1e-12)\n",
        "\n",
        "def cross_entropy(probs, y_onehot):\n",
        "    return -np.mean(np.sum(y_onehot * np.log(probs + 1e-12), axis=1))\n",
        "\n",
        "def macro_f1(y_true, y_pred, num_classes=12):\n",
        "    f1s = []\n",
        "    for c in range(1, num_classes + 1):\n",
        "        tp = np.sum((y_pred == c) & (y_true == c))\n",
        "        fp = np.sum((y_pred == c) & (y_true != c))\n",
        "        fn = np.sum((y_pred != c) & (y_true == c))\n",
        "        prec = tp / (tp + fp + 1e-12)\n",
        "        rec = tp / (tp + fn + 1e-12)\n",
        "        f1 = 2 * prec * rec / (prec + rec + 1e-12)\n",
        "        f1s.append(f1)\n",
        "    return float(np.mean(f1s))\n",
        "\n",
        "# LayerNorm\n",
        "\n",
        "class LayerNorm:\n",
        "    def __init__(self, dim, eps=1e-5):\n",
        "        self.gamma = np.ones((1, dim), dtype=np.float32)\n",
        "        self.beta  = np.zeros((1, dim), dtype=np.float32)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        self.mean = x.mean(axis=1, keepdims=True)\n",
        "        self.var  = x.var(axis=1, keepdims=True)\n",
        "        self.norm = (x - self.mean) / np.sqrt(self.var + self.eps)\n",
        "        return self.gamma * self.norm + self.beta\n",
        "\n",
        "    def backward(self, grad):\n",
        "        N, D = grad.shape\n",
        "        gamma = self.gamma\n",
        "\n",
        "        dnorm = grad * gamma\n",
        "        dvar  = np.sum(dnorm * (self.x - self.mean) * -0.5 *\n",
        "                       (self.var + self.eps)**(-3/2), axis=1, keepdims=True)\n",
        "        dmean = np.sum(dnorm * -1 / np.sqrt(self.var + self.eps), axis=1, keepdims=True) \\\n",
        "                + dvar * np.mean(-2 * (self.x - self.mean), axis=1, keepdims=True)\n",
        "\n",
        "        dx = dnorm / np.sqrt(self.var + self.eps) \\\n",
        "             + dvar * 2 * (self.x - self.mean) / D \\\n",
        "             + dmean / D\n",
        "\n",
        "        self.dgamma = np.sum(grad * self.norm, axis=0, keepdims=True)\n",
        "        self.dbeta  = np.sum(grad, axis=0, keepdims=True)\n",
        "        return dx\n",
        "\n",
        "# LSTM with Backward (Full)\n",
        "\n",
        "class LSTM:\n",
        "    def __init__(self, input_dim, hidden_dim, rng):\n",
        "        self.in_dim = input_dim\n",
        "        self.h_dim = hidden_dim\n",
        "        lim = np.sqrt(1.0 / (input_dim + hidden_dim))\n",
        "\n",
        "        self.Wx = rng.uniform(-lim, lim, (input_dim, 4 * hidden_dim)).astype(np.float32)\n",
        "        self.Wh = rng.uniform(-lim, lim, (hidden_dim, 4 * hidden_dim)).astype(np.float32)\n",
        "        self.b  = np.zeros((4 * hidden_dim,), dtype=np.float32)\n",
        "\n",
        "    def forward(self, X):\n",
        "        N, T, D = X.shape\n",
        "        H = self.h_dim\n",
        "\n",
        "        self.x_list = []\n",
        "        self.i_list = []\n",
        "        self.f_list = []\n",
        "        self.o_list = []\n",
        "        self.g_list = []\n",
        "        self.c_list = []\n",
        "        self.h_list = []\n",
        "\n",
        "        h = np.zeros((N, H), dtype=np.float32)\n",
        "        c = np.zeros((N, H), dtype=np.float32)\n",
        "\n",
        "        self.c_list.append(c.copy())\n",
        "        self.h_list.append(h.copy())\n",
        "\n",
        "        for t in range(T):\n",
        "            x_t = X[:, t, :]\n",
        "            a = x_t @ self.Wx + h @ self.Wh + self.b\n",
        "\n",
        "            i = 1 / (1 + np.exp(-a[:, :H]))\n",
        "            f = 1 / (1 + np.exp(-a[:, H:2*H]))\n",
        "            o = 1 / (1 + np.exp(-a[:, 2*H:3*H]))\n",
        "            g = np.tanh(a[:, 3*H:])\n",
        "\n",
        "            c = f * c + i * g\n",
        "            h = o * np.tanh(c)\n",
        "\n",
        "            self.x_list.append(x_t)\n",
        "            self.i_list.append(i)\n",
        "            self.f_list.append(f)\n",
        "            self.o_list.append(o)\n",
        "            self.g_list.append(g)\n",
        "            self.c_list.append(c.copy())\n",
        "            self.h_list.append(h.copy())\n",
        "\n",
        "        return np.stack(self.h_list[1:], axis=1)\n",
        "\n",
        "\n",
        "    def backward(self, dh_last):\n",
        "        N, H = dh_last.shape\n",
        "        T = len(self.x_list)\n",
        "\n",
        "        dWx = np.zeros_like(self.Wx)\n",
        "        dWh = np.zeros_like(self.Wh)\n",
        "        db  = np.zeros_like(self.b)\n",
        "\n",
        "        dx = np.zeros((N, T, self.in_dim), dtype=np.float32)\n",
        "\n",
        "        dh_next = dh_last\n",
        "        dc_next = np.zeros((N, H), dtype=np.float32)\n",
        "\n",
        "        for t in reversed(range(T)):\n",
        "            x_t = self.x_list[t]\n",
        "            i = self.i_list[t]\n",
        "            f = self.f_list[t]\n",
        "            o = self.o_list[t]\n",
        "            g = self.g_list[t]\n",
        "            c_t = self.c_list[t+1]\n",
        "            c_prev = self.c_list[t]\n",
        "            h_prev = self.h_list[t]\n",
        "\n",
        "            tanh_c = np.tanh(c_t)\n",
        "\n",
        "            do = dh_next * tanh_c\n",
        "            dc = dh_next * o * (1 - tanh_c**2) + dc_next\n",
        "\n",
        "            df = dc * c_prev\n",
        "            di = dc * g\n",
        "            dg = dc * i\n",
        "            dc_prev = dc * f\n",
        "\n",
        "            di_in = di * i * (1 - i)\n",
        "            df_in = df * f * (1 - f)\n",
        "            do_in = do * o * (1 - o)\n",
        "            dg_in = dg * (1 - g**2)\n",
        "\n",
        "            da = np.concatenate([di_in, df_in, do_in, dg_in], axis=1)\n",
        "\n",
        "            dWx += x_t.T @ da\n",
        "            dWh += h_prev.T @ da\n",
        "            db  += da.sum(axis=0)\n",
        "\n",
        "            dx[:, t, :] = da @ self.Wx.T\n",
        "            dh_prev = da @ self.Wh.T\n",
        "\n",
        "            dh_next = dh_prev\n",
        "            dc_next = dc_prev\n",
        "\n",
        "        self.dWx, self.dWh, self.db = dWx, dWh, db\n",
        "        return dx\n",
        "\n",
        "# Dense\n",
        "class Dense:\n",
        "    def __init__(self, in_dim, out_dim, rng):\n",
        "        lim = np.sqrt(6.0/(in_dim + out_dim))\n",
        "        self.W = rng.uniform(-lim, lim, (in_dim, out_dim)).astype(np.float32)\n",
        "        self.b = np.zeros((out_dim,), dtype=np.float32)\n",
        "\n",
        "        self.mW = np.zeros_like(self.W)\n",
        "        self.vW = np.zeros_like(self.W)\n",
        "        self.mb = np.zeros_like(self.b)\n",
        "        self.vb = np.zeros_like(self.b)\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        return x @ self.W + self.b\n",
        "\n",
        "class SimpleLSTMPlus:\n",
        "\n",
        "    def __init__(self, T, D, H=256, num_classes=12):\n",
        "        rng = np.random.RandomState(42)\n",
        "\n",
        "        self.lstm = LSTM(D, H, rng)\n",
        "        self.norm = LayerNorm(H)\n",
        "\n",
        "        # attention parameters\n",
        "        self.att_w = rng.uniform(-0.1, 0.1, (H, 1)).astype(np.float32)\n",
        "\n",
        "        self.fc1 = Dense(H, 128, rng)\n",
        "        self.fc2 = Dense(128, num_classes, rng)\n",
        "\n",
        "        self.lr = 7e-4\n",
        "        self.beta1=0.9; self.beta2=0.999\n",
        "        self.eps = 1e-8\n",
        "        self.t = 0\n",
        "\n",
        "        self.dropout = 0.25\n",
        "        self.training = True\n",
        "\n",
        "\n",
        "    def _adam(self, param, grad, m, v):\n",
        "        self.t += 1\n",
        "        m[:] = self.beta1*m + (1-self.beta1)*grad\n",
        "        v[:] = self.beta2*v + (1-self.beta2)*(grad*grad)\n",
        "        mhat = m / (1 - self.beta1**self.t)\n",
        "        vhat = v / (1 - self.beta2**self.t)\n",
        "        param -= self.lr * mhat / (np.sqrt(vhat) + self.eps)\n",
        "\n",
        "\n",
        "    def forward(self, X):\n",
        "        hs = self.lstm.forward(X)                 # (N,T,H)\n",
        "\n",
        "        # LayerNorm\n",
        "        N,T,H = hs.shape\n",
        "        hs_norm = self.norm.forward(hs.reshape(N*T, H)).reshape(N, T, H)\n",
        "\n",
        "        # attention score\n",
        "        score = hs_norm @ self.att_w              # (N,T,1)\n",
        "        score = np.exp(score - score.max(axis=1,keepdims=True))\n",
        "        att = score / (score.sum(axis=1, keepdims=True)+1e-12)\n",
        "\n",
        "        # weighted pooling\n",
        "        h_att = (hs_norm * att).sum(axis=1)        # (N,H)\n",
        "\n",
        "        if self.training:\n",
        "            mask = (np.random.rand(*h_att.shape) > self.dropout).astype(np.float32)\n",
        "            h_att = h_att * mask / (1 - self.dropout)\n",
        "\n",
        "        z1 = self.fc1.forward(h_att)\n",
        "        h1 = np.maximum(z1, 0)\n",
        "\n",
        "        logits = self.fc2.forward(h1)\n",
        "        return logits, h1, h_att, hs_norm, att\n",
        "\n",
        "\n",
        "    def step(self):\n",
        "        clip = 5.0\n",
        "        for g in [self.fc2.dW, self.fc2.db, self.fc1.dW, self.fc1.db,\n",
        "                  self.lstm.dWx, self.lstm.dWh, self.lstm.db]:\n",
        "            np.clip(g, -clip, clip, out=g)\n",
        "\n",
        "        # FC updates\n",
        "        self._adam(self.fc2.W, self.fc2.dW, self.fc2.mW, self.fc2.vW)\n",
        "        self._adam(self.fc2.b, self.fc2.db, self.fc2.mb, self.fc2.vb)\n",
        "        self._adam(self.fc1.W, self.fc1.dW, self.fc1.mW, self.fc1.vW)\n",
        "        self._adam(self.fc1.b, self.fc1.db, self.fc1.mb, self.fc1.vb)\n",
        "\n",
        "        # LSTM updates\n",
        "        self._adam(self.lstm.Wx, self.lstm.dWx, np.zeros_like(self.lstm.Wx), np.zeros_like(self.lstm.Wx))\n",
        "        self._adam(self.lstm.Wh, self.lstm.dWh, np.zeros_like(self.lstm.Wh), np.zeros_like(self.lstm.Wh))\n",
        "        self._adam(self.lstm.b,  self.lstm.db,  np.zeros_like(self.lstm.b),  np.zeros_like(self.lstm.b))\n",
        "\n",
        "\n",
        "    def fit(self, Xtr, ytr, Xte, yte, epochs=15, batch=64):\n",
        "        N = Xtr.shape[0]\n",
        "        idxs = np.arange(N)\n",
        "\n",
        "        for ep in range(1, epochs+1):\n",
        "            np.random.shuffle(idxs)\n",
        "            self.training = True\n",
        "            losses = []\n",
        "\n",
        "            for i in range(0, N, batch):\n",
        "                b_idx = idxs[i:i+batch]\n",
        "                xb = Xtr[b_idx]\n",
        "                yb = ytr[b_idx]\n",
        "                yb_oh = one_hot(yb, 12)\n",
        "\n",
        "                logits, h1, h_att, hs_norm, att = self.forward(xb)\n",
        "                probs = softmax(logits)\n",
        "                loss = cross_entropy(probs, yb_oh)\n",
        "                losses.append(loss)\n",
        "\n",
        "                # backward: Dense2\n",
        "                dlogits = (probs - yb_oh) / batch\n",
        "                self.fc2.dW = h1.T @ dlogits\n",
        "                self.fc2.db = dlogits.sum(axis=0)\n",
        "\n",
        "                # backward: Dense1 (ReLU)\n",
        "                dh1 = dlogits @ self.fc2.W.T\n",
        "                drelu = dh1 * (h1 > 0)\n",
        "\n",
        "                self.fc1.dW = self.fc1.x.T @ drelu\n",
        "                self.fc1.db = drelu.sum(axis=0)\n",
        "\n",
        "                # backward: LSTM ← h_att\n",
        "                dh_att = drelu @ self.fc1.W.T\n",
        "                dhs = np.repeat(dh_att[:,None,:], Xtr.shape[1], axis=1)\n",
        "                self.lstm.backward(dhs.mean(axis=1))\n",
        "\n",
        "                self.step()\n",
        "\n",
        "            self.training = False\n",
        "            pred = self.predict(Xte)\n",
        "            f1 = macro_f1(yte, pred, 12)\n",
        "            print(f\"[Epoch {ep}] loss={np.mean(losses):.4f} | macroF1(te)={f1:.4f}\")\n",
        "\n",
        "        return f1\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        logits, *_ = self.forward(X)\n",
        "        return np.argmax(softmax(logits), axis=1) + 1\n"
      ],
      "metadata": {
        "id": "aAL20t5vQJeX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XVu7RQq8OlmJ"
      },
      "outputs": [],
      "source": [
        "def run_lstm_crossval(X_all, y_all, s_all, pairs, epochs=15, batch=64, lr=1e-3):\n",
        "    f1s = []\n",
        "    for i, pair in enumerate(pairs, 1):\n",
        "        X_tr, y_tr, X_te, y_te = split_by_subject(X_all, y_all, s_all, pair)\n",
        "        X_tr, X_te, mean, std = standardize(X_tr, X_te)\n",
        "\n",
        "        model = SimpleLSTMPlus(T=X_tr.shape[1], D=X_tr.shape[2], H=256)\n",
        "        model.lr = lr\n",
        "\n",
        "        print(f\"\\n=== Fold {i} | Test subjects={pair} ===\")\n",
        "        f1 = model.fit(X_tr, y_tr, X_te, y_te, epochs=epochs, batch=batch)\n",
        "        f1s.append(f1)\n",
        "\n",
        "        acc = np.mean(model.predict(X_te) == y_te)\n",
        "        print(f\"Fold {i} done. Acc={acc:.4f}, Macro-F1={f1:.4f}\")\n",
        "\n",
        "    print(\"\\n=== Summary ===\")\n",
        "    print(\"Per-fold:\", [f\"{v:.4f}\" for v in f1s])\n",
        "    print(\"Mean:\", np.mean(f1s))\n",
        "    return f1s, float(np.mean(f1s))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noyevkq4OtHx",
        "outputId": "31a9d531-bc9c-4702-fb2b-f4cf4193edac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 1 | Test subjects=(1, 2) ===\n",
            "[Epoch 1] loss=0.5831 | macroF1(te)=0.6180\n",
            "[Epoch 2] loss=0.1533 | macroF1(te)=0.7459\n",
            "[Epoch 3] loss=0.1914 | macroF1(te)=0.7669\n",
            "[Epoch 4] loss=0.1420 | macroF1(te)=0.7074\n",
            "[Epoch 5] loss=0.1322 | macroF1(te)=0.8128\n",
            "[Epoch 6] loss=0.1189 | macroF1(te)=0.6490\n",
            "[Epoch 7] loss=0.2355 | macroF1(te)=0.6849\n",
            "[Epoch 8] loss=0.1017 | macroF1(te)=0.7758\n",
            "[Epoch 9] loss=0.1646 | macroF1(te)=0.6168\n",
            "[Epoch 10] loss=0.1664 | macroF1(te)=0.6910\n",
            "[Epoch 11] loss=0.1246 | macroF1(te)=0.7191\n",
            "[Epoch 12] loss=0.1607 | macroF1(te)=0.8207\n",
            "[Epoch 13] loss=0.1852 | macroF1(te)=0.6941\n",
            "[Epoch 14] loss=0.1549 | macroF1(te)=0.8318\n",
            "[Epoch 15] loss=0.1191 | macroF1(te)=0.7954\n",
            "Fold 1 done. Acc=0.7881, Macro-F1=0.7954\n",
            "\n",
            "=== Fold 2 | Test subjects=(3, 4) ===\n",
            "[Epoch 1] loss=0.5737 | macroF1(te)=0.8051\n",
            "[Epoch 2] loss=0.1929 | macroF1(te)=0.8436\n",
            "[Epoch 3] loss=0.1668 | macroF1(te)=0.8177\n",
            "[Epoch 4] loss=0.3267 | macroF1(te)=0.7680\n",
            "[Epoch 5] loss=0.1590 | macroF1(te)=0.8093\n",
            "[Epoch 6] loss=0.1439 | macroF1(te)=0.9076\n",
            "[Epoch 7] loss=0.1749 | macroF1(te)=0.7989\n",
            "[Epoch 8] loss=0.1937 | macroF1(te)=0.7148\n",
            "[Epoch 9] loss=0.2350 | macroF1(te)=0.8260\n",
            "[Epoch 10] loss=0.1652 | macroF1(te)=0.9005\n",
            "[Epoch 11] loss=0.1229 | macroF1(te)=0.8821\n",
            "[Epoch 12] loss=0.1581 | macroF1(te)=0.8274\n",
            "[Epoch 13] loss=0.1371 | macroF1(te)=0.7556\n",
            "[Epoch 14] loss=0.1305 | macroF1(te)=0.7921\n",
            "[Epoch 15] loss=0.1445 | macroF1(te)=0.8542\n",
            "Fold 2 done. Acc=0.8816, Macro-F1=0.8542\n",
            "\n",
            "=== Fold 3 | Test subjects=(5, 6) ===\n",
            "[Epoch 1] loss=0.5475 | macroF1(te)=0.7618\n",
            "[Epoch 2] loss=0.2472 | macroF1(te)=0.6918\n",
            "[Epoch 3] loss=0.1804 | macroF1(te)=0.7806\n",
            "[Epoch 4] loss=0.1671 | macroF1(te)=0.7875\n",
            "[Epoch 5] loss=0.1244 | macroF1(te)=0.8021\n",
            "[Epoch 6] loss=0.1644 | macroF1(te)=0.7624\n",
            "[Epoch 7] loss=0.1676 | macroF1(te)=0.8695\n",
            "[Epoch 8] loss=0.1266 | macroF1(te)=0.8805\n",
            "[Epoch 9] loss=0.1452 | macroF1(te)=0.7878\n",
            "[Epoch 10] loss=0.2273 | macroF1(te)=0.8718\n",
            "[Epoch 11] loss=0.1401 | macroF1(te)=0.8228\n",
            "[Epoch 12] loss=0.1262 | macroF1(te)=0.7955\n",
            "[Epoch 13] loss=0.1248 | macroF1(te)=0.8493\n",
            "[Epoch 14] loss=0.1193 | macroF1(te)=0.8606\n",
            "[Epoch 15] loss=0.1425 | macroF1(te)=0.7461\n",
            "Fold 3 done. Acc=0.7689, Macro-F1=0.7461\n",
            "\n",
            "=== Fold 4 | Test subjects=(7, 8) ===\n",
            "[Epoch 1] loss=0.5836 | macroF1(te)=0.5662\n",
            "[Epoch 2] loss=0.2998 | macroF1(te)=0.7906\n",
            "[Epoch 3] loss=0.2322 | macroF1(te)=0.7198\n",
            "[Epoch 4] loss=0.2650 | macroF1(te)=0.7311\n",
            "[Epoch 5] loss=0.2337 | macroF1(te)=0.7965\n",
            "[Epoch 6] loss=0.1407 | macroF1(te)=0.9031\n",
            "[Epoch 7] loss=0.1325 | macroF1(te)=0.8510\n",
            "[Epoch 8] loss=0.1417 | macroF1(te)=0.8212\n",
            "[Epoch 9] loss=0.1405 | macroF1(te)=0.8592\n",
            "[Epoch 10] loss=0.1249 | macroF1(te)=0.8911\n",
            "[Epoch 11] loss=0.1601 | macroF1(te)=0.8702\n",
            "[Epoch 12] loss=0.1118 | macroF1(te)=0.7711\n",
            "[Epoch 13] loss=0.1468 | macroF1(te)=0.8911\n",
            "[Epoch 14] loss=0.1278 | macroF1(te)=0.7832\n",
            "[Epoch 15] loss=0.1652 | macroF1(te)=0.8609\n",
            "Fold 4 done. Acc=0.8629, Macro-F1=0.8609\n",
            "\n",
            "=== Fold 5 | Test subjects=(9, 10) ===\n",
            "[Epoch 1] loss=0.6290 | macroF1(te)=0.8652\n",
            "[Epoch 2] loss=0.1876 | macroF1(te)=0.8731\n",
            "[Epoch 3] loss=0.2304 | macroF1(te)=0.7712\n",
            "[Epoch 4] loss=0.2184 | macroF1(te)=0.7548\n",
            "[Epoch 5] loss=0.1982 | macroF1(te)=0.7529\n",
            "[Epoch 6] loss=0.1769 | macroF1(te)=0.8969\n",
            "[Epoch 7] loss=0.1649 | macroF1(te)=0.8365\n",
            "[Epoch 8] loss=0.1681 | macroF1(te)=0.7968\n",
            "[Epoch 9] loss=0.1060 | macroF1(te)=0.9279\n",
            "[Epoch 10] loss=0.1112 | macroF1(te)=0.8323\n",
            "[Epoch 11] loss=0.1321 | macroF1(te)=0.8697\n",
            "[Epoch 12] loss=0.1563 | macroF1(te)=0.8246\n",
            "[Epoch 13] loss=0.1276 | macroF1(te)=0.9035\n",
            "[Epoch 14] loss=0.1373 | macroF1(te)=0.9203\n",
            "[Epoch 15] loss=0.1070 | macroF1(te)=0.9261\n",
            "Fold 5 done. Acc=0.9264, Macro-F1=0.9261\n",
            "\n",
            "=== Summary ===\n",
            "Per-fold: ['0.7954', '0.8542', '0.7461', '0.8609', '0.9261']\n",
            "Mean: 0.8365184061930091\n",
            "\n",
            "최종 평균 Macro-F1 (LSTM): 0.8365184061930091\n"
          ]
        }
      ],
      "source": [
        "f1s_lstm, mean_f1_lstm = run_lstm_crossval(\n",
        "    X_all, y_all, s_all, pairs,\n",
        "    epochs=15, batch=64, lr=1e-3\n",
        ")\n",
        "\n",
        "print(\"\\n최종 평균 Macro-F1 (LSTM):\", mean_f1_lstm)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "13TN7tJpTZu_lMzQFf69lEg_C2gG1YWSF",
      "authorship_tag": "ABX9TyNVFLKGbfCY6uUXFr3jpa2M",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
