{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1lweuRPsTBUEIviKkzigKiRFqkdd6oL08",
      "authorship_tag": "ABX9TyOYm+OFDP+uAeQ74inTljJL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Heoyuna0819/machine_learning/blob/main/Mhealth_CNN%2BLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZTx_VODtsOs",
        "outputId": "46b970e7-73c6-441c-8a1e-9a3166488747"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(343195, 25)\n",
            "   chest_acc_x  chest_acc_y  chest_acc_z     ecg_1     ecg_2  ankle_acc_x  \\\n",
            "0      -9.7788      0.55690      1.19750  0.008373 -0.033490       2.6493   \n",
            "1      -9.7733      0.27880      0.73036 -0.025118 -0.025118       2.4157   \n",
            "2      -9.8609      0.11561      0.79988  0.025118  0.016745       2.3865   \n",
            "3      -9.7409      0.17652      0.88957  0.180010  0.129770       2.3758   \n",
            "4      -9.7821      0.21637      0.90368  0.092098  0.046049       2.3239   \n",
            "\n",
            "   ankle_acc_y  ankle_acc_z  ankle_gyro_x  ankle_gyro_y  ...  arm_acc_y  \\\n",
            "0      -9.4517      0.37683      -0.20965      -0.88931  ...    -9.0618   \n",
            "1      -9.5306      0.40179      -0.20965      -0.88931  ...    -9.2048   \n",
            "2      -9.5991      0.48141      -0.20037      -0.86867  ...    -9.1945   \n",
            "3      -9.5997      0.42919      -0.20037      -0.86867  ...    -9.1746   \n",
            "4      -9.5406      0.40038      -0.20037      -0.86867  ...    -9.2039   \n",
            "\n",
            "   arm_acc_z  arm_gyro_x  arm_gyro_y  arm_gyro_z  arm_mag_x  arm_mag_y  \\\n",
            "0     1.8177   -0.058824    -0.93429    -0.34483   0.355370   -0.37003   \n",
            "1     1.5189   -0.058824    -0.93429    -0.34483   0.719910    0.17803   \n",
            "2     1.5507   -0.058824    -0.93429    -0.34483   0.355370   -0.37003   \n",
            "3     1.5413   -0.078431    -0.93429    -0.34052   0.357180   -0.18858   \n",
            "4     1.6127   -0.078431    -0.93429    -0.34052  -0.001887   -0.18867   \n",
            "\n",
            "   arm_mag_z  label  subject  \n",
            "0   -0.35020      1        1  \n",
            "1    0.37363      1        1  \n",
            "2   -0.35020      1        1  \n",
            "3   -0.35198      1        1  \n",
            "4   -0.72017      1        1  \n",
            "\n",
            "[5 rows x 25 columns]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 데이터셋 경로 설정\n",
        "DATA_DIR = \"/content/drive/MyDrive/MHEALTHDATASET\"\n",
        "\n",
        "# UCI MHEALTH dataset 컬럼 정의\n",
        "COLS = [\n",
        "    \"chest_acc_x\",\"chest_acc_y\",\"chest_acc_z\",\n",
        "    \"ecg_1\",\"ecg_2\",\n",
        "    \"ankle_acc_x\",\"ankle_acc_y\",\"ankle_acc_z\",\n",
        "    \"ankle_gyro_x\",\"ankle_gyro_y\",\"ankle_gyro_z\",\n",
        "    \"ankle_mag_x\",\"ankle_mag_y\",\"ankle_mag_z\",\n",
        "    \"arm_acc_x\",\"arm_acc_y\",\"arm_acc_z\",\n",
        "    \"arm_gyro_x\",\"arm_gyro_y\",\"arm_gyro_z\",\n",
        "    \"arm_mag_x\",\"arm_mag_y\",\"arm_mag_z\",\n",
        "    \"label\"\n",
        "]\n",
        "\n",
        "# 모든 subject 데이터 읽어서 합치기\n",
        "dfs = []\n",
        "for sid in range(1, 11):  # subject 1~10\n",
        "    file_path = os.path.join(DATA_DIR, f\"mHealth_subject{sid}.log\")\n",
        "    df = pd.read_csv(file_path, sep=\"\\t\", header=None, names=COLS)\n",
        "    df[\"subject\"] = sid   # subject 번호 추가\n",
        "    dfs.append(df)\n",
        "\n",
        "# 하나의 DataFrame으로 합치기\n",
        "full_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Null 클래스(라벨=0)는 제거\n",
        "full_df = full_df[full_df[\"label\"] != 0].reset_index(drop=True)\n",
        "\n",
        "print(full_df.shape)\n",
        "print(full_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 윈도우 크기 & stride\n",
        "FS = 50          # 주파수 50Hz\n",
        "WIN = 2 * FS     # 2초 = 100 샘플\n",
        "STRIDE = WIN // 2  # 절반 겹치기 = 50 샘플\n",
        "\n",
        "# feature 컬럼 (라벨과 subject 제외)\n",
        "FEATURE_COLS = [c for c in full_df.columns if c not in [\"label\", \"subject\"]]\n",
        "\n",
        "def make_windows_by_subject(df, min_ratio=0.0):\n",
        "    Xs, ys, subs = [], [], []\n",
        "\n",
        "    # subject별로 안전하게 자르기\n",
        "    for sid, part in df.groupby(\"subject\", sort=True):\n",
        "        arr = part[FEATURE_COLS].values.astype(np.float32)  # (N_s, 23)\n",
        "        labels = part[\"label\"].values.astype(np.int32)      # (N_s,)\n",
        "        n = len(part)\n",
        "        i = 0\n",
        "        while i + WIN <= n:\n",
        "            w_labels = labels[i:i+WIN]\n",
        "            w_vals = arr[i:i+WIN]\n",
        "\n",
        "            # 최빈값(label)과 비율\n",
        "            binc = np.bincount(w_labels)\n",
        "            maj = np.argmax(binc)\n",
        "            maj_ratio = binc[maj] / WIN\n",
        "\n",
        "            if maj_ratio >= min_ratio:\n",
        "                Xs.append(w_vals)\n",
        "                ys.append(maj)\n",
        "                subs.append(sid)\n",
        "\n",
        "            i += STRIDE\n",
        "\n",
        "    X = np.array(Xs)             # (num_windows, 100, 23)\n",
        "    y = np.array(ys, dtype=int)  # (num_windows,)\n",
        "    s = np.array(subs, dtype=int)\n",
        "    return X, y, s\n",
        "\n",
        "X_all, y_all, s_all = make_windows_by_subject(full_df, min_ratio=0.0)\n",
        "\n",
        "print(\"X_all shape:\", X_all.shape)\n",
        "print(\"y_all shape:\", y_all.shape)\n",
        "print(\"subject unique:\", np.unique(s_all))\n",
        "# 라벨 1~12 분포\n",
        "counts = np.bincount(y_all)\n",
        "print(\"라벨 분포(1~12):\", counts[1:13])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOE9kX8jt5vb",
        "outputId": "ca1504ca-de61-4061-a347-a471a71110f3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_all shape: (6849, 100, 23)\n",
            "y_all shape: (6849,)\n",
            "subject unique: [ 1  2  3  4  5  6  7  8  9 10]\n",
            "라벨 분포(1~12): [610 615 615 614 608 567 587 587 614 614 616 202]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 5개 그룹\n",
        "pairs = [(1,2), (3,4), (5,6), (7,8), (9,10)]\n",
        "\n",
        "def split_by_subject(X, y, s, test_pair):\n",
        "    \"\"\"\n",
        "    X: 윈도우 입력 데이터 (shape: [N, T, D])\n",
        "    y: 라벨 (shape: [N])\n",
        "    s: subject 번호 (shape: [N])\n",
        "    test_pair: (예: (1,2)) 테스트 subject 번호 쌍\n",
        "    \"\"\"\n",
        "    test_mask = np.isin(s, test_pair)   # 테스트셋에 해당하는 subject만 True\n",
        "    X_train, y_train = X[~test_mask], y[~test_mask]\n",
        "    X_test,  y_test  = X[test_mask],  y[test_mask]\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "# 다섯 fold 순환\n",
        "for i, pair in enumerate(pairs, 1):\n",
        "    X_tr, y_tr, X_te, y_te = split_by_subject(X_all, y_all, s_all, pair)\n",
        "    print(f\"Fold {i} | Test subjects={pair}\")\n",
        "    print(\"  Train set:\", X_tr.shape, y_tr.shape)\n",
        "    print(\"  Test set :\", X_te.shape, y_te.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDIH0KYzt8lB",
        "outputId": "8fc91b98-d7a6-46dd-a72f-bf4325c3db9a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 | Test subjects=(1, 2)\n",
            "  Train set: (5438, 100, 23) (5438,)\n",
            "  Test set : (1411, 100, 23) (1411,)\n",
            "Fold 2 | Test subjects=(3, 4)\n",
            "  Train set: (5438, 100, 23) (5438,)\n",
            "  Test set : (1411, 100, 23) (1411,)\n",
            "Fold 3 | Test subjects=(5, 6)\n",
            "  Train set: (5529, 100, 23) (5529,)\n",
            "  Test set : (1320, 100, 23) (1320,)\n",
            "Fold 4 | Test subjects=(7, 8)\n",
            "  Train set: (5500, 100, 23) (5500,)\n",
            "  Test set : (1349, 100, 23) (1349,)\n",
            "Fold 5 | Test subjects=(9, 10)\n",
            "  Train set: (5491, 100, 23) (5491,)\n",
            "  Test set : (1358, 100, 23) (1358,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 5개 그룹\n",
        "pairs = [(1,2), (3,4), (5,6), (7,8), (9,10)]\n",
        "\n",
        "def split_by_subject(X, y, s, test_pair):\n",
        "    test_mask = np.isin(s, test_pair)\n",
        "    X_train, y_train = X[~test_mask], y[~test_mask]\n",
        "    X_test,  y_test  = X[test_mask],  y[test_mask]\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "def standardize(train_X, test_X):\n",
        "\n",
        "    # 훈련 데이터 기준으로 mean/std 계산\n",
        "    mean = train_X.mean(axis=(0,1), keepdims=True)\n",
        "    std = train_X.std(axis=(0,1), keepdims=True)\n",
        "    std[std == 0] = 1.0\n",
        "\n",
        "    # 표준화 적용\n",
        "    train_X = (train_X - mean) / std\n",
        "    test_X  = (test_X  - mean) / std\n",
        "    return train_X, test_X, mean, std\n",
        "\n",
        "# 5-Fold 교차검증용 루프\n",
        "for i, pair in enumerate(pairs, 1):\n",
        "    X_tr, y_tr, X_te, y_te = split_by_subject(X_all, y_all, s_all, pair)\n",
        "    X_tr, X_te, mean, std = standardize(X_tr, X_te)\n",
        "\n",
        "    print(f\"Fold {i} | Test subjects={pair}\")\n",
        "    print(\"  Train set:\", X_tr.shape, y_tr.shape)\n",
        "    print(\"  Test set :\", X_te.shape, y_te.shape)\n",
        "    print(\"  평균:\", np.round(mean.mean(), 3), \" | 표준편차:\", np.round(std.mean(), 3))\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XOjlimNt_FT",
        "outputId": "85276088-dff0-416a-c72a-5212d395a2ca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 | Test subjects=(1, 2)\n",
            "  Train set: (5438, 100, 23) (5438,)\n",
            "  Test set : (1411, 100, 23) (1411,)\n",
            "  평균: -1.097  | 표준편차: 14.805\n",
            "--------------------------------------------------\n",
            "Fold 2 | Test subjects=(3, 4)\n",
            "  Train set: (5438, 100, 23) (5438,)\n",
            "  Test set : (1411, 100, 23) (1411,)\n",
            "  평균: -1.105  | 표준편차: 14.749\n",
            "--------------------------------------------------\n",
            "Fold 3 | Test subjects=(5, 6)\n",
            "  Train set: (5529, 100, 23) (5529,)\n",
            "  Test set : (1320, 100, 23) (1320,)\n",
            "  평균: -1.076  | 표준편차: 14.514\n",
            "--------------------------------------------------\n",
            "Fold 4 | Test subjects=(7, 8)\n",
            "  Train set: (5500, 100, 23) (5500,)\n",
            "  Test set : (1349, 100, 23) (1349,)\n",
            "  평균: -1.137  | 표준편차: 14.941\n",
            "--------------------------------------------------\n",
            "Fold 5 | Test subjects=(9, 10)\n",
            "  Train set: (5491, 100, 23) (5491,)\n",
            "  Test set : (1358, 100, 23) (1358,)\n",
            "  평균: -1.045  | 표준편차: 14.942\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed=42):\n",
        "    return np.random.RandomState(seed)\n",
        "\n",
        "def one_hot(y, num_classes):\n",
        "    oh = np.zeros((len(y), num_classes), np.float32)\n",
        "    oh[np.arange(len(y)), y-1] = 1\n",
        "    return oh\n",
        "\n",
        "def softmax(x):\n",
        "    x = x - x.max(axis=1, keepdims=True)\n",
        "    e = np.exp(x)\n",
        "    return e / (e.sum(axis=1, keepdims=True)+1e-12)\n",
        "\n",
        "def cross_entropy(p, yoh):\n",
        "    return -np.mean(np.sum(yoh*np.log(p+1e-12), axis=1))\n",
        "\n",
        "def macro_f1(yt, yp, K=12):\n",
        "    f1s=[]\n",
        "    for c in range(1,K+1):\n",
        "        tp = np.sum((yp==c)&(yt==c))\n",
        "        fp = np.sum((yp==c)&(yt!=c))\n",
        "        fn = np.sum((yp!=c)&(yt==c))\n",
        "        p = tp/(tp+fp+1e-12)\n",
        "        r = tp/(tp+fn+1e-12)\n",
        "        f1 = 2*p*r/(p+r+1e-12)\n",
        "        f1s.append(f1)\n",
        "    return float(np.mean(f1s))\n",
        "\n",
        "class Conv1D:\n",
        "    def __init__(self, k, c_in, c_out, rng):\n",
        "        lim = np.sqrt(6/(k*c_in+c_out))\n",
        "        self.W = rng.uniform(-lim, lim, (k,c_in,c_out)).astype(np.float32)\n",
        "        self.b = np.zeros((c_out,), np.float32)\n",
        "        self.mW=np.zeros_like(self.W); self.vW=np.zeros_like(self.W)\n",
        "        self.mb=np.zeros_like(self.b); self.vb=np.zeros_like(self.b)\n",
        "\n",
        "        self.dW = np.zeros_like(self.W)\n",
        "        self.db = np.zeros_like(self.b)\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        N,T,C = x.shape\n",
        "        k,_,Cout = self.W.shape\n",
        "        To = T-k+1\n",
        "        out = np.zeros((N,To,Cout), np.float32)\n",
        "        for t in range(To):\n",
        "            out[:,t,:] = np.tensordot(x[:,t:t+k,:], self.W, axes=([1,2],[0,1])) + self.b\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        x = self.x\n",
        "        N,T,C = x.shape\n",
        "        k,_,Cout = self.W.shape\n",
        "        To = T-k+1\n",
        "\n",
        "        dW = np.zeros_like(self.W)\n",
        "        db = dout.sum((0,1))\n",
        "        dx = np.zeros_like(x)\n",
        "\n",
        "        for t in range(To):\n",
        "            xs = x[:, t:t+k, :]\n",
        "            dW += np.tensordot(xs, dout[:,t,:], axes=([0],[0]))\n",
        "            dx[:, t:t+k, :] += np.tensordot(dout[:,t,:], self.W, axes=([1],[2]))\n",
        "\n",
        "        self.dW, self.db = dW, db\n",
        "        return dx\n",
        "\n",
        "class ReLU:\n",
        "    def forward(self, x):\n",
        "        self.mask = (x>0)\n",
        "        return x*self.mask\n",
        "    def backward(self, dout):\n",
        "        return dout*self.mask\n",
        "\n",
        "class MaxPool1D:\n",
        "    def __init__(self, pool=2, stride=2):\n",
        "        self.pool=pool\n",
        "        self.stride=stride\n",
        "\n",
        "    def forward(self,x):\n",
        "        self.x=x\n",
        "        N,T,C = x.shape\n",
        "        To = 1+(T-self.pool)//self.stride\n",
        "        out = np.zeros((N,To,C),np.float32)\n",
        "        self.argmax = np.zeros((N,To,C),np.int32)\n",
        "        for t in range(To):\n",
        "            s=t*self.stride\n",
        "            w=x[:,s:s+self.pool,:]\n",
        "            idx = np.argmax(w,axis=1)\n",
        "            out[:,t,:]=w[np.arange(N)[:,None], idx, np.arange(C)]\n",
        "            self.argmax[:,t,:]=s+idx\n",
        "        return out\n",
        "\n",
        "    def backward(self,dout):\n",
        "        x=self.x\n",
        "        N,T,C=x.shape\n",
        "        _,To,_=dout.shape\n",
        "        dx=np.zeros_like(x)\n",
        "        for t in range(To):\n",
        "            idx=self.argmax[:,t,:]\n",
        "            for n in range(N):\n",
        "                dx[n, idx[n,:], np.arange(C)] += dout[n,t,:]\n",
        "        return dx\n",
        "\n",
        "class Dense:\n",
        "    def __init__(self, in_dim, out_dim, rng):\n",
        "        lim=np.sqrt(6/(in_dim+out_dim))\n",
        "        self.W=rng.uniform(-lim,lim,(in_dim,out_dim)).astype(np.float32)\n",
        "        self.b=np.zeros((out_dim,),np.float32)\n",
        "\n",
        "        self.mW=np.zeros_like(self.W); self.vW=np.zeros_like(self.W)\n",
        "        self.mb=np.zeros_like(self.b); self.vb=np.zeros_like(self.b)\n",
        "\n",
        "        self.dW = np.zeros_like(self.W)\n",
        "        self.db = np.zeros_like(self.b)\n",
        "\n",
        "    def forward(self,x):\n",
        "        self.x=x\n",
        "        return x@self.W+self.b\n",
        "\n",
        "    def backward(self,dout):\n",
        "        self.dW=self.x.T@dout\n",
        "        self.db=dout.sum(0)\n",
        "        return dout@self.W.T\n",
        ""
      ],
      "metadata": {
        "id": "YdZjzgPM2iyy"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. LSTM\n",
        "\n",
        "class LSTM:\n",
        "    def __init__(self, D, H, rng):\n",
        "        self.D = D\n",
        "        self.H = H\n",
        "        lim = np.sqrt(1.0 / (D + H))\n",
        "\n",
        "        self.Wx = rng.uniform(-lim, lim, (D, 4*H)).astype(np.float32)\n",
        "        self.Wh = rng.uniform(-lim, lim, (H, 4*H)).astype(np.float32)\n",
        "        self.b  = np.zeros((4*H,), np.float32)\n",
        "\n",
        "        # Adam 용 변수\n",
        "        self.mWx = np.zeros_like(self.Wx); self.vWx = np.zeros_like(self.Wx)\n",
        "        self.mWh = np.zeros_like(self.Wh); self.vWh = np.zeros_like(self.Wh)\n",
        "        self.mb  = np.zeros_like(self.b);  self.vb  = np.zeros_like(self.b)\n",
        "\n",
        "        # gradient 버퍼\n",
        "        self.dWx = np.zeros_like(self.Wx)\n",
        "        self.dWh = np.zeros_like(self.Wh)\n",
        "        self.db  = np.zeros_like(self.b)\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        X: (N, T, D)\n",
        "        return hs: (N, T, H)\n",
        "        \"\"\"\n",
        "        N, T, D = X.shape\n",
        "        H = self.H\n",
        "\n",
        "        self.x_list = []\n",
        "        self.i_list = []\n",
        "        self.f_list = []\n",
        "        self.o_list = []\n",
        "        self.g_list = []\n",
        "        self.c_list = []\n",
        "        self.h_list = []\n",
        "\n",
        "        h = np.zeros((N, H), np.float32)\n",
        "        c = np.zeros((N, H), np.float32)\n",
        "\n",
        "        self.h_list.append(h.copy())\n",
        "        self.c_list.append(c.copy())\n",
        "\n",
        "        hs = np.zeros((N, T, H), np.float32)\n",
        "\n",
        "        for t in range(T):\n",
        "            x_t = X[:, t, :]\n",
        "            self.x_list.append(x_t)\n",
        "\n",
        "            a = x_t @ self.Wx + h @ self.Wh + self.b  # (N,4H)\n",
        "            i = 1.0 / (1.0 + np.exp(-a[:, :H]))\n",
        "            f = 1.0 / (1.0 + np.exp(-a[:, H:2*H]))\n",
        "            o = 1.0 / (1.0 + np.exp(-a[:, 2*H:3*H]))\n",
        "            g = np.tanh(a[:, 3*H:])\n",
        "\n",
        "            c = f * c + i * g\n",
        "            h = o * np.tanh(c)\n",
        "\n",
        "            self.i_list.append(i)\n",
        "            self.f_list.append(f)\n",
        "            self.o_list.append(o)\n",
        "            self.g_list.append(g)\n",
        "            self.c_list.append(c.copy())\n",
        "            self.h_list.append(h.copy())\n",
        "\n",
        "            hs[:, t, :] = h\n",
        "\n",
        "        return hs\n",
        "\n",
        "    def backward(self, dhs):\n",
        "        \"\"\"\n",
        "        dhs: (N, T, H)  ← 모든 시점의 hidden에 대한 gradient\n",
        "        return dx: (N, T, D)\n",
        "        \"\"\"\n",
        "        N, T, H = dhs.shape\n",
        "        D = self.D\n",
        "\n",
        "        dWx = np.zeros_like(self.Wx)\n",
        "        dWh = np.zeros_like(self.Wh)\n",
        "        db  = np.zeros_like(self.b)\n",
        "        dx  = np.zeros((N, T, D), np.float32)\n",
        "\n",
        "        dh_next = np.zeros((N, H), np.float32)\n",
        "        dc_next = np.zeros((N, H), np.float32)\n",
        "\n",
        "        for t in reversed(range(T)):\n",
        "            # 이번 타임스텝에서 내려온 grad + 다음 스텝에서 온 grad\n",
        "            dh = dhs[:, t, :] + dh_next\n",
        "\n",
        "            x_t = self.x_list[t]\n",
        "            i = self.i_list[t]\n",
        "            f = self.f_list[t]\n",
        "            o = self.o_list[t]\n",
        "            g = self.g_list[t]\n",
        "            c_t = self.c_list[t+1]\n",
        "            c_prev = self.c_list[t]\n",
        "            h_prev = self.h_list[t]\n",
        "\n",
        "            tanh_c = np.tanh(c_t)\n",
        "\n",
        "            do = dh * tanh_c\n",
        "            dc = dh * o * (1.0 - tanh_c**2) + dc_next\n",
        "\n",
        "            df = dc * c_prev\n",
        "            di = dc * g\n",
        "            dg = dc * i\n",
        "            dc_prev = dc * f\n",
        "\n",
        "            di_in = di * i * (1.0 - i)\n",
        "            df_in = df * f * (1.0 - f)\n",
        "            do_in = do * o * (1.0 - o)\n",
        "            dg_in = dg * (1.0 - g**2)\n",
        "\n",
        "            da = np.concatenate([di_in, df_in, do_in, dg_in], axis=1)  # (N,4H)\n",
        "\n",
        "            dWx += x_t.T @ da\n",
        "            dWh += h_prev.T @ da\n",
        "            db  += da.sum(axis=0)\n",
        "\n",
        "            dx[:, t, :] = da @ self.Wx.T\n",
        "            dh_prev     = da @ self.Wh.T\n",
        "\n",
        "            dh_next = dh_prev\n",
        "            dc_next = dc_prev\n",
        "\n",
        "        self.dWx, self.dWh, self.db = dWx, dWh, db\n",
        "        return dx\n",
        "\n",
        "# 2. BiLSTM (정방향 + 역방향)\n",
        "class BiLSTM:\n",
        "    def __init__(self, D, H, rng):\n",
        "        self.fwd = LSTM(D, H, rng)\n",
        "        self.bwd = LSTM(D, H, rng)\n",
        "        self.H = H\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        X: (N,T,D)\n",
        "        return hs_bi: (N,T,2H)\n",
        "        \"\"\"\n",
        "        hs_f = self.fwd.forward(X)               # (N,T,H)\n",
        "        hs_b = self.bwd.forward(X[:, ::-1, :])   # (N,T,H)\n",
        "        hs_b = hs_b[:, ::-1, :]                  # 다시 원래 순서로\n",
        "        return np.concatenate([hs_f, hs_b], axis=2)  # (N,T,2H)\n",
        "\n",
        "    def backward(self, dhs_bi):\n",
        "        \"\"\"\n",
        "        dhs_bi: (N,T,2H)\n",
        "        return dx: (N,T,D)\n",
        "        \"\"\"\n",
        "        N, T, HH = dhs_bi.shape\n",
        "        H = HH // 2\n",
        "\n",
        "        dhs_f = dhs_bi[:, :, :H]\n",
        "        dhs_b = dhs_bi[:, :, H:]\n",
        "\n",
        "        # 역방향 LSTM은 시퀀스 뒤집어서 전달\n",
        "        dhs_b_rev = dhs_b[:, ::-1, :]\n",
        "        dx_f = self.fwd.backward(dhs_f)          # (N,T,D)\n",
        "        dx_b_rev = self.bwd.backward(dhs_b_rev)  # (N,T,D)\n",
        "        dx_b = dx_b_rev[:, ::-1, :]\n",
        "\n",
        "        return dx_f + dx_b\n",
        "\n",
        "\n",
        "\n",
        "# 3. CNN + BiLSTM + Attention 모델\n",
        "class CNN_BiLSTM_Att_Stable:\n",
        "    def __init__(self, T, D, H=96, num_classes=12, rng=None):\n",
        "        self.rng = set_seed(42) if rng is None else rng\n",
        "\n",
        "        # ---- CNN 부분 (얕게 1개 + 풀링) ----\n",
        "        self.conv1 = Conv1D(k=5, c_in=D, c_out=64, rng=self.rng)\n",
        "        self.relu1 = ReLU()\n",
        "        self.pool1 = MaxPool1D(pool=2, stride=2)   # 100 -> 96 -> 48\n",
        "\n",
        "        # ---- BiLSTM ----\n",
        "        self.bilstm = BiLSTM(D=64, H=H, rng=self.rng)  # 출력: (N,T', 2H)\n",
        "\n",
        "        # ---- Attention (time-wise) ----\n",
        "        self.att_w = self.rng.uniform(-0.1, 0.1, (2*H, 1)).astype(np.float32)\n",
        "        self.m_att = np.zeros_like(self.att_w)\n",
        "        self.v_att = np.zeros_like(self.att_w)\n",
        "        self.d_att_w = np.zeros_like(self.att_w)\n",
        "\n",
        "        # ---- FC ----\n",
        "        self.fc1 = Dense(in_dim=2*H, out_dim=64, rng=self.rng)\n",
        "        self.relu_fc = ReLU()\n",
        "        self.fc2 = Dense(in_dim=64, out_dim=num_classes, rng=self.rng)\n",
        "\n",
        "        # Adam 하이퍼파라미터\n",
        "        self.t = 0\n",
        "        self.lr = 5e-4\n",
        "        self.b1 = 0.9\n",
        "        self.b2 = 0.999\n",
        "        self.eps = 1e-8\n",
        "        self.clip = 3.0\n",
        "\n",
        "    # ----- Adam helper -----\n",
        "    def _adam(self, param, grad, m, v):\n",
        "        self.t += 1\n",
        "        m[:] = self.b1 * m + (1 - self.b1) * grad\n",
        "        v[:] = self.b2 * v + (1 - self.b2) * (grad * grad)\n",
        "        mhat = m / (1 - self.b1**self.t)\n",
        "        vhat = v / (1 - self.b2**self.t)\n",
        "        param -= self.lr * mhat / (np.sqrt(vhat) + self.eps)\n",
        "\n",
        "    # ----- Forward -----\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        X: (N,T,D)\n",
        "        return logits: (N, num_classes)\n",
        "        \"\"\"\n",
        "        # CNN\n",
        "        z = self.conv1.forward(X)\n",
        "        z = self.relu1.forward(z)\n",
        "        z = self.pool1.forward(z)        # (N, T', 64)\n",
        "\n",
        "        # BiLSTM\n",
        "        hs = self.bilstm.forward(z)      # (N, T', 2H)\n",
        "        self.hs = hs\n",
        "\n",
        "        # Attention\n",
        "        # score: (N, T', 1)\n",
        "        score = hs @ self.att_w          # (N,T',1)\n",
        "        score = score - score.max(axis=1, keepdims=True)\n",
        "        exp_s = np.exp(score)\n",
        "        att = exp_s / (exp_s.sum(axis=1, keepdims=True) + 1e-12)\n",
        "        self.att = att                   # (N,T',1)\n",
        "\n",
        "        # context: (N, 2H)\n",
        "        h_att = (hs * att).sum(axis=1)   # (N,2H)\n",
        "        self.h_att = h_att\n",
        "\n",
        "        # FC\n",
        "        h1 = self.fc1.forward(h_att)     # (N,64)\n",
        "        h1 = self.relu_fc.forward(h1)\n",
        "        self.h1 = h1\n",
        "\n",
        "        logits = self.fc2.forward(h1)    # (N,12)\n",
        "        return logits\n",
        "\n",
        "    # ----- Backward -----\n",
        "    def backward(self, dlogits):\n",
        "        \"\"\"\n",
        "        dlogits: (N, num_classes)\n",
        "        \"\"\"\n",
        "        # FC2\n",
        "        dh1 = self.fc2.backward(dlogits)     # (N,64)\n",
        "        dh1 = self.relu_fc.backward(dh1)     # (N,64)\n",
        "        dh_att = self.fc1.backward(dh1)      # (N,2H)\n",
        "\n",
        "        # ----- Attention backward -----\n",
        "        hs = self.hs          # (N,T,2H)\n",
        "        att = self.att        # (N,T,1)\n",
        "        N, T, HH = hs.shape\n",
        "\n",
        "        # context = sum_t att_t * hs_t\n",
        "        # → dhs_from_context\n",
        "        dh_att_exp = dh_att[:, None, :]      # (N,1,2H)\n",
        "        dhs_ctx = att * dh_att_exp           # (N,T,2H)\n",
        "\n",
        "        # d alpha\n",
        "        # alpha_t = att_t\n",
        "        # dL/dalpha_t = dh_att · hs_t\n",
        "        dalpha = np.sum(dh_att_exp * hs, axis=2, keepdims=True)   # (N,T,1)\n",
        "\n",
        "        # softmax backward: ds = alpha * (dalpha - sum(dalpha*alpha))\n",
        "        sum_dalpha_alpha = np.sum(dalpha * att, axis=1, keepdims=True)  # (N,1,1)\n",
        "        ds = att * (dalpha - sum_dalpha_alpha)                          # (N,T,1)\n",
        "\n",
        "        # d w_att\n",
        "        # score_t = hs_t @ w_att → dL/dw = sum_{n,t} hs[n,t]^T * ds[n,t]\n",
        "        d_att_w = np.zeros_like(self.att_w)     # (2H,1)\n",
        "        # hs: (N,T,2H), ds: (N,T,1)\n",
        "        d_att_w[:, 0] = np.sum(hs * ds, axis=(0,1))\n",
        "\n",
        "        # d hs from score: ds @ w_att^T\n",
        "        dhs_score = ds @ self.att_w.T           # (N,T,2H)\n",
        "\n",
        "        dhs_total = dhs_ctx + dhs_score         # (N,T,2H)\n",
        "        self.d_att_w = d_att_w\n",
        "\n",
        "        # ----- BiLSTM backward -----\n",
        "        dz = self.bilstm.backward(dhs_total)    # (N,T',64)\n",
        "\n",
        "        # ----- CNN backward -----\n",
        "        dz = self.pool1.backward(dz)            # (N, 96, 64)\n",
        "        dz = self.relu1.backward(dz)\n",
        "        dz = self.conv1.backward(dz)            # conv1.dW, conv1.db 계산됨\n",
        "\n",
        "    # ----- Step (Adam + clipping) -----\n",
        "    def step(self):\n",
        "        params = [\n",
        "            (self.conv1.W, self.conv1.dW, self.conv1.mW, self.conv1.vW),\n",
        "            (self.conv1.b, self.conv1.db, self.conv1.mb, self.conv1.vb),\n",
        "\n",
        "            (self.bilstm.fwd.Wx, self.bilstm.fwd.dWx, self.bilstm.fwd.mWx, self.bilstm.fwd.vWx),\n",
        "            (self.bilstm.fwd.Wh, self.bilstm.fwd.dWh, self.bilstm.fwd.mWh, self.bilstm.fwd.vWh),\n",
        "            (self.bilstm.fwd.b , self.bilstm.fwd.db , self.bilstm.fwd.mb , self.bilstm.fwd.vb),\n",
        "\n",
        "            (self.bilstm.bwd.Wx, self.bilstm.bwd.dWx, self.bilstm.bwd.mWx, self.bilstm.bwd.vWx),\n",
        "            (self.bilstm.bwd.Wh, self.bilstm.bwd.dWh, self.bilstm.bwd.mWh, self.bilstm.bwd.vWh),\n",
        "            (self.bilstm.bwd.b , self.bilstm.bwd.db , self.bilstm.bwd.mb , self.bilstm.bwd.vb),\n",
        "\n",
        "            (self.att_w, self.d_att_w, self.m_att, self.v_att),\n",
        "\n",
        "            (self.fc1.W, self.fc1.dW, self.fc1.mW, self.fc1.vW),\n",
        "            (self.fc1.b, self.fc1.db, self.fc1.mb, self.fc1.vb),\n",
        "            (self.fc2.W, self.fc2.dW, self.fc2.mW, self.fc2.vW),\n",
        "            (self.fc2.b, self.fc2.db, self.fc2.mb, self.fc2.vb)\n",
        "        ]\n",
        "\n",
        "        # gradient clipping\n",
        "        for _, g, _, _ in params:\n",
        "            np.clip(g, -self.clip, self.clip, out=g)\n",
        "\n",
        "        # Adam 업데이트\n",
        "        for p, g, m, v in params:\n",
        "            self._adam(p, g, m, v)\n",
        "\n",
        "    def predict(self, X):\n",
        "        logits = self.forward(X)\n",
        "        probs = softmax(logits)\n",
        "        return np.argmax(probs, axis=1) + 1\n",
        "\n",
        "\n",
        "# 4. Cross-validation 함수\n",
        "\n",
        "def run_cnn_bilstm_att_crossval(\n",
        "    X_all, y_all, s_all, pairs,\n",
        "    epochs=8, batch=32, lr=5e-4\n",
        "):\n",
        "    f1s = []\n",
        "    for i, pair in enumerate(pairs, 1):\n",
        "        print(f\"\\n=== Fold {i} | Test subjects={pair} ===\")\n",
        "\n",
        "        X_tr, y_tr, X_te, y_te = split_by_subject(X_all, y_all, s_all, pair)\n",
        "        X_tr, X_te, mean, std = standardize(X_tr, X_te)\n",
        "\n",
        "        model = CNN_BiLSTM_Att_Stable(\n",
        "            T=X_tr.shape[1],\n",
        "            D=X_tr.shape[2],\n",
        "            H=96,\n",
        "            num_classes=12\n",
        "        )\n",
        "        model.lr = lr\n",
        "\n",
        "        N = len(X_tr)\n",
        "        idx = np.arange(N)\n",
        "\n",
        "        for ep in range(1, epochs+1):\n",
        "            np.random.shuffle(idx)\n",
        "            losses = []\n",
        "\n",
        "            for j in range(0, N, batch):\n",
        "                b = idx[j:j+batch]\n",
        "                xb = X_tr[b]\n",
        "                yb = y_tr[b]\n",
        "                yb_oh = one_hot(yb, 12)\n",
        "\n",
        "                logits = model.forward(xb)\n",
        "                probs = softmax(logits)\n",
        "                loss = cross_entropy(probs, yb_oh)\n",
        "                losses.append(loss)\n",
        "\n",
        "                dlogits = (probs - yb_oh) / len(b)\n",
        "                model.backward(dlogits)\n",
        "                model.step()\n",
        "\n",
        "            # 에폭마다 테스트 F1 출력\n",
        "            pred = model.predict(X_te)\n",
        "            f1 = macro_f1(y_te, pred, 12)\n",
        "            print(f\"[Epoch {ep}] loss={np.mean(losses):.4f} | F1={f1:.4f}\")\n",
        "\n",
        "        # 폴드 최종 평가\n",
        "        pred = model.predict(X_te)\n",
        "        f1 = macro_f1(y_te, pred, 12)\n",
        "        acc = np.mean(pred == y_te)\n",
        "        print(f\"Fold {i} done. Acc={acc:.4f} | F1={f1:.4f}\")\n",
        "        f1s.append(f1)\n",
        "\n",
        "    print(\"\\n==== Summary ====\")\n",
        "    print(\"Per-fold F1:\", [f\"{v:.4f}\" for v in f1s])\n",
        "    print(\"Mean F1:\", np.mean(f1s))\n",
        "    return f1s, float(np.mean(f1s))\n",
        "\n",
        "# 5. 실행\n",
        "\n",
        "f1s_best, mean_f1_best = run_cnn_bilstm_att_crossval(\n",
        "    X_all, y_all, s_all, pairs,\n",
        "    epochs=8, batch=32, lr=5e-4\n",
        ")\n",
        "\n",
        "print(\"\\n최종 평균 Macro-F1 (CNN+BiLSTM+Att, 안정형):\", mean_f1_best)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rFmHFAt-Jib",
        "outputId": "297f7538-fef7-4adf-bc5d-1c777fc0a68c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 1 | Test subjects=(1, 2) ===\n",
            "[Epoch 1] loss=0.4147 | F1=0.7291\n",
            "[Epoch 2] loss=0.0176 | F1=0.7853\n",
            "[Epoch 3] loss=0.0092 | F1=0.7223\n",
            "[Epoch 4] loss=0.0039 | F1=0.8132\n",
            "[Epoch 5] loss=0.0029 | F1=0.8042\n",
            "[Epoch 6] loss=0.0010 | F1=0.8046\n",
            "[Epoch 7] loss=0.0005 | F1=0.8048\n",
            "[Epoch 8] loss=0.0004 | F1=0.8091\n",
            "Fold 1 done. Acc=0.8249 | F1=0.8091\n",
            "\n",
            "=== Fold 2 | Test subjects=(3, 4) ===\n",
            "[Epoch 1] loss=0.4489 | F1=0.8928\n",
            "[Epoch 2] loss=0.0276 | F1=0.9106\n",
            "[Epoch 3] loss=0.0160 | F1=0.9030\n",
            "[Epoch 4] loss=0.0080 | F1=0.9136\n",
            "[Epoch 5] loss=0.0039 | F1=0.9054\n",
            "[Epoch 6] loss=0.0012 | F1=0.9057\n",
            "[Epoch 7] loss=0.0006 | F1=0.9092\n",
            "[Epoch 8] loss=0.0004 | F1=0.9090\n",
            "Fold 2 done. Acc=0.9079 | F1=0.9090\n",
            "\n",
            "=== Fold 3 | Test subjects=(5, 6) ===\n",
            "[Epoch 1] loss=0.4311 | F1=0.8164\n",
            "[Epoch 2] loss=0.0388 | F1=0.8944\n",
            "[Epoch 3] loss=0.0193 | F1=0.8830\n",
            "[Epoch 4] loss=0.0067 | F1=0.8928\n",
            "[Epoch 5] loss=0.0072 | F1=0.8943\n",
            "[Epoch 6] loss=0.0065 | F1=0.8954\n",
            "[Epoch 7] loss=0.0026 | F1=0.8981\n",
            "[Epoch 8] loss=0.0008 | F1=0.8960\n",
            "Fold 3 done. Acc=0.8917 | F1=0.8960\n",
            "\n",
            "=== Fold 4 | Test subjects=(7, 8) ===\n",
            "[Epoch 1] loss=0.4249 | F1=0.7317\n",
            "[Epoch 2] loss=0.0414 | F1=0.8401\n",
            "[Epoch 3] loss=0.0181 | F1=0.8298\n",
            "[Epoch 4] loss=0.0136 | F1=0.8202\n",
            "[Epoch 5] loss=0.0049 | F1=0.8238\n",
            "[Epoch 6] loss=0.0022 | F1=0.8120\n",
            "[Epoch 7] loss=0.0028 | F1=0.8076\n",
            "[Epoch 8] loss=0.0022 | F1=0.8252\n",
            "Fold 4 done. Acc=0.8258 | F1=0.8252\n",
            "\n",
            "=== Fold 5 | Test subjects=(9, 10) ===\n",
            "[Epoch 1] loss=0.4541 | F1=0.9581\n",
            "[Epoch 2] loss=0.0385 | F1=0.9890\n",
            "[Epoch 3] loss=0.0174 | F1=0.9764\n",
            "[Epoch 4] loss=0.0088 | F1=0.9637\n",
            "[Epoch 5] loss=0.0044 | F1=0.9887\n",
            "[Epoch 6] loss=0.0015 | F1=0.9917\n",
            "[Epoch 7] loss=0.0008 | F1=0.9914\n",
            "[Epoch 8] loss=0.0005 | F1=0.9929\n",
            "Fold 5 done. Acc=0.9934 | F1=0.9929\n",
            "\n",
            "==== Summary ====\n",
            "Per-fold F1: ['0.8091', '0.9090', '0.8960', '0.8252', '0.9929']\n",
            "Mean F1: 0.8864389848274137\n",
            "\n",
            "최종 평균 Macro-F1 (CNN+BiLSTM+Att, 안정형): 0.8864389848274137\n"
          ]
        }
      ]
    }
  ]
}